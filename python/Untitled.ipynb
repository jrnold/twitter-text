{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport twittertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"emoticons.txt\", 'r') as f:\n",
    "    data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ruamel.yaml\n",
    "import os.path\n",
    "conformance_dir = \"../conformance/\"\n",
    "tests = {}\n",
    "for fname in os.listdir(conformance_dir):\n",
    "    if os.path.splitext(fname)[1] == '.yml':\n",
    "        with open(os.path.join(conformance_dir, fname), encoding='utf8') as f:\n",
    "            key = os.path.splitext(fname)[0]\n",
    "            tests[key] = ruamel.yaml.load(f, Loader=ruamel.yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"#hashtag here and #here and #another, #11\"\n",
    "hashtags = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twittertext.NON_BMP_CODE_PAIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twittertext.NON_BMP_CODE_PAIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twittertext.ASTRAL_NUMERALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twittertext.ASTRAL_LETTERS_AND_MARKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twittertext.HASHTAG_ALPHA_NUMERIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test in tests['extract']['tests']['hashtags_from_astral']:\n",
    "    hashtags = twittertext.extract_hashtags(test['text'])\n",
    "    if hashtags != test['expected']:\n",
    "        print(re.findall(\"[\" + twittertext.ASTRAL_LETTERS_AND_MARKS + \"]\", test['text']))\n",
    "        print(test['description'])\n",
    "        print(test['text'].encode())\n",
    "        print(test['text'], \":\", test['expected'], hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test in tests['extract']['tests']['hashtags']:\n",
    "    hashtags = twittertext.extract_hashtags(test['text'])\n",
    "    if hashtags != test['expected']:\n",
    "        print(test['description'])\n",
    "        print(test['text'], \":\", test['expected'], hashtags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#PUNCT = r\"!'#%&()*+,\\\\./:;<=>?@[\\]^_{|}~$-\"\n",
    "#CASHTAG = r\"[a-z]{1,6}(?:[._][a-z]{1,2})?\"\n",
    "#VALID_CASHTAG = r\"(?:\\$)(?P<cashtag>[a-z]{1,6})\"\n",
    "#VALID_CASHTAG = fr\"(?:^|(?<=[{twittertext.SPACES}]))(\\$)(?P<cashtag>{CASHTAG})(?:$|\\s|[{PUNCT}])\"\n",
    "print(twittertext.RE_VALID_CASHTAG)\n",
    "for test in tests['extract']['tests']['cashtags']:\n",
    "    cashtags = twittertext.extract_cashtags(test['text'])\n",
    "    if cashtags != test['expected']:\n",
    "        print(\"failed\")      \n",
    "        print(test['description'])\n",
    "        print(test['text'], \":\", test['expected'], cashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[tests['extract']['tests'].keys()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(twittertext.PUNCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CASHTAG = r\"(?:[a-z]{1,6}(?:[._][a-z]{1,2})?)\"\n",
    "VALID_CASHTAG = r\"(?:^|[{SPACES}])(?:\\$)(?P<cashtag>{CASHTAG})(?:$|\\s|[{PUNCT}])\".\\\n",
    "    format(CASHTAG=CASHTAG, PUNCT=twittertext.PUNCT, SPACES=twittertext.SPACES)\n",
    "text = \"$TEST.T $test.tt $Stock_X $symbol_ab\"\n",
    "re.findall(VALID_CASHTAG, text, re.I)\n",
    "'$' in 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for test in tests['extract']['tests']['cashtags']:\n",
    "    hashtags = twittertext.extract_hashtags(test['text'])\n",
    "    if hashtags != test['expected']:\n",
    "        print(test['description'])\n",
    "        print(test['text'], \":\", test['expected'], hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(twittertext.RE_VALID_MENTION_OR_LIST)\n",
    "for test in tests['extract']['tests']['mentions']:\n",
    "    print(test['description'])\n",
    "    mentions = twittertext.extract_mentions(test['text'])\n",
    "    if test['expected'] != mentions:\n",
    "        print(test['text'])\n",
    "        print(\"Expected: \", test['expected'])\n",
    "        print(\"Actual: \", mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(twittertext.RE_VALID_MENTION_OR_LIST)\n",
    "for test in tests['extract']['tests']['mentions_or_lists_with_indices']:\n",
    "    print()\n",
    "    print(test['description'])\n",
    "    mentions = twittertext.extract_mentions_with_indices(test['text'])\n",
    "    if test['expected'] != mentions:\n",
    "        print(test['text'])\n",
    "        print(\"Expected: \", test['expected'])\n",
    "        print(\"Actual: \", mentions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(twittertext.RE_VALID_REPLY)\n",
    "for test in tests['extract']['tests']['replies']:\n",
    "    print(test['description'])\n",
    "    replies = twittertext.extract_replies(test['text'])\n",
    "    if test['expected'] != replies:\n",
    "        print(test['text'])\n",
    "        print(\"Expected: \", test['expected'])\n",
    "        print(\"Actual: \", replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(tests['extract']['tests'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 20), match='http://t.co/pbY2NfTZ'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.match(twittertext.VALID_TCO_URL, 'http://t.co/pbY2NfTZ', flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile(\"\\n      (?P<before> (?:[^A-Za-z0-9@＠$#＃\\ufffe\\ufeff\\uffff\\u202a-\\u202e]|^) )\\n      (?P<url>\\n        (?P<protocol> https?:// ) ?\\n        (?P<domain> (?:(?:(?:[^!'#%&()*+,\\\\\\\\./:;<=>?@[\\\\]^_{|}~$\\\\-, re.IGNORECASE|re.VERBOSE)\n",
      "Extract a lone URL\n",
      "Extract valid URL: http://google.com\n",
      "Extract valid URL: http://foobar.com/#\n",
      "Extract valid URL: http://google.com/#foo\n",
      "Extract valid URL: http://google.com/#search?q=iphone%20-filter%3Alinks\n",
      "Extract valid URL: http://twitter.com/#search?q=iphone%20-filter%3Alinks\n",
      "Extract valid URL: http://somedomain.com/index.php?path=/abc/def/\n",
      "Extract valid URL: http://www.boingboing.net/2007/02/14/katamari_damacy_phon.html\n",
      "Extract valid URL: http://somehost.com:3000\n",
      "Extract valid URL: http://xo.com/~matthew+%ff-x\n",
      "Extract valid URL: http://xo.com/~matthew+%ff-,.;x\n",
      "Extract valid URL: http://xo.com/,.;x\n",
      "Extract valid URL: http://en.wikipedia.org/wiki/Primer_(film)\n",
      "Extract valid URL: http://www.ams.org/bookstore-getitem/item=mbk-59\n",
      "Extract valid URL: http://✪df.ws/ejp\n",
      "Extract valid URL: http://chilp.it/?77e8fd\n",
      "Extract valid URL: http://x.com/oneletterdomain\n",
      "Extract valid URL: http://msdn.microsoft.com/ja-jp/library/system.net.httpwebrequest(v=VS.100).aspx\n",
      "DO NOT extract invalid URL: http://domain-begin_dash_2314352345_dfasd.foo-cow_4352.com\n",
      "DO NOT extract invalid URL: http://-begin_dash_2314352345_dfasd.foo-cow_4352.com\n",
      "DO NOT extract invalid URL: http://no-tld\n",
      "DO NOT extract invalid URL: http://tld-too-short.x\n",
      "DO NOT extract invalid URL with invalid preceding character: (http://twitter.com\n",
      "Extract a very long hyphenated sub-domain URL (single letter hyphens)\n",
      "Extract a hyphenated TLD (usually a typo)\n",
      "Extract URL ending with # value\n",
      "Extract URLs without protocol on (com|org|edu|gov|net) domains\n",
      "Extract URLs without protocol not on (com|org|edu|gov|net) domains\n",
      "Extract URLs without protocol on ccTLD with slash\n",
      "Extract URLs with protocol on ccTLD domains\n",
      "Extract URLs with a - or + at the end of the path\n",
      "Extract URLs with longer paths ending in -\n",
      "Extract URLs with an en dash in the path\n",
      "Extract URLs beginning with a space\n",
      "Extract long URL without protocol surrounded by CJK characters\n",
      "Extract short URL without protocol surrounded by CJK characters\n",
      "Extract URLs with and without protocol surrounded by CJK characters\n",
      "Extract URLs with protocol and path containing Cyrillic characters\n",
      "DO NOT extract short URLs without protocol on ccTLD domains without path\n",
      "Extract some (tv|co) short URLs without protocol on ccTLD domains without path\n",
      "Extract URLs beginning with a non-breaking space (U+00A0)\n",
      "Extract URLs with underscores and dashes in the subdomain\n",
      "Extract URL with minimum number of valid characters\n",
      "Extract URLs containing underscores and dashes\n",
      "Extract URLs containing dashes in the subdomain\n",
      "Extract URLs with dashes in the domain name\n",
      "Extract URLs with lots of symbols then a period\n",
      "DO NOT extract URLs containing leading dashes in the subdomain\n",
      "DO NOT extract URLs containing trailing dashes in the subdomain\n",
      "DO NOT extract URLs containing leading underscores in the subdomain\n",
      "DO NOT extract URLs containing trailing underscores in the subdomain\n",
      "DO NOT extract URLs containing leading dashes in the domain name\n",
      "DO NOT extract URLs containing trailing dashes in the domain name\n",
      "DO NOT extract URLs containing underscores in the domain name\n",
      "DO NOT extract URLs containing underscores in the tld\n",
      "Extract valid URL http://www.foo.com/foo/path-with-period./\n",
      "Extract valid URL http://www.foo.org.za/foo/bar/688.1\n",
      "Extract valid URL http://www.foo.com/bar-path/some.stm?param1=foo;param2=P1|0||P2|0\n",
      "Extract valid URL http://foo.com/bar/123/foo_&_bar/\n",
      "Extract valid URL http://www.cp.sc.edu/events/65\n",
      "Extract valid URL http://www.andersondaradio.no.comunidades.net/\n",
      "Extract valid URL ELPAÍS.com\n",
      "DO NOT include period at the end of URL\n",
      "Extract a URL with '?' in fragment\n",
      "Extract a URL with '?' in fragment in a text\n",
      "Extract a URL with a ton of trailing periods\n",
      "Extract a URL with a ton of trailing commas\n",
      "Extract a URL with a ton of trailing '!'\n",
      "DO NOT extract URLs in hashtag or @mention\n",
      "Extract a t.co URL with a trailing apostrophe\n",
      "Extract a t.co URL with a trailing hyphen\n",
      "Extract a t.co URL with a trailing colon\n",
      "Extract URL before newline\n",
      "DO NOT extract URL if preceded by $\n",
      "DO NOT extract .bz2 file name as URL\n",
      "DO NOT extract URL with gTLD followed by @ sign\n",
      "DO NOT extract URL with ccTLD followed by @ sign\n"
     ]
    }
   ],
   "source": [
    "print(twittertext.RE_EXTRACT_URL)\n",
    "for test in tests['extract']['tests']['urls']:\n",
    "    print(test['description'])\n",
    "    urls = twittertext.extract_urls(test['text'], without_protocol=True)\n",
    "    if test['expected'] != urls:\n",
    "        print(\"\\t\", test['text'])\n",
    "        print(\"\\t\", \"Expected: \", test['expected'])\n",
    "        print(\"\\t\", \"Actual: \", urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile(\"\\n      (?P<before> (?:[^A-Za-z0-9@＠$#＃\\ufffe\\ufeff\\uffff\\u202a-\\u202e]|^) )\\n      (?P<url>\\n        (?P<protocol> https?:// ) ?\\n        (?P<domain> (?:(?:(?:[^!'#%&()*+,\\\\\\\\./:;<=>?@[\\\\]^_{|}~$\\\\-, re.IGNORECASE|re.VERBOSE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 18), match='http://example.com'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(twittertext.RE_EXTRACT_URL)\n",
    "twittertext.RE_EXTRACT_URL.search(\"http://example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for combining regexes, like `regexSupplant` in `twitter-text.js`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _sre\n",
    "def get_pattern(x):\n",
    "    \"\"\" Return regex pattern\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return getattr(x, 'pattern')\n",
    "    except AttributeError:\n",
    "        return str(x)\n",
    "    \n",
    "def get_flags(x):\n",
    "    try:\n",
    "        return getattr(x, 'flags')\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "    \n",
    "def regex_combine(pattern, flags=0, **kwargs):\n",
    "    replacements = {k: get_pattern(x) for k, x in kwargs.items()}\n",
    "    flags = flags + sum(get_flags(x) for x in kwargs.values())\n",
    "    return re.compile(pattern.format(**replacements), flags=flags)\n",
    "\n",
    "def add_pattern(x, key, pattern):\n",
    "    x[key] = pattern.format(**x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex_combine(\"{foo}\", foo = re.compile(\"[abc]\", flags = re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ca1596f6ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\\u1F468\\u200D\\u1F468\\u200D\\u1F467\\u200D\\u1F466\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
